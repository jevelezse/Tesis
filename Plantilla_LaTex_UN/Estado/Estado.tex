\chapter{Estado del Arte}

\section{Biología molecular y secuenciación masiva.}

Desde  que  Watson y Crick propusieron la estructura del ADN en 1953 \cite{Watson1953}, el estudio del ADN ha sido básico en el desarrollo de la biología molecular, incluso el mismo Francis Crick fue quien propuso el dogma central de la misma para describir la relevancia del ADN en los seres vivos y la utilización de la información que contiene por las células,dada la importancia del  ADN  en las décadas de 1970 y 1980 se desarrollaron  técnicas para determinar el orden de los nucleótidos  (técnicas de secuenciación) de manera más eficiente que la secuenciación de las proteínas y se definieron secuencias de algunos organismos como el virus de Episten Barr y  de la mitocondria humana, mediante la utilización de métodos químicos propuestos por Maxam y Gilbert en 1977 y Sanger en 1980 siendo este último el más popular, estas técnicas son conocidas como tecnicas primera generación \cite{Herraez2012}. 

Los métodos desarrollados para secuenciar prosperaron y con el proyecto del genoma humano que comenzó en 1980 y fue completado en el 2003, permitió que se desarrollaran nuevas tecnologías para optimizar el proceso de secuenciación y disminuir sus costos, inicialmente fue el secuenciador de Illumina  que en el 2008 permitió obtener el primer individuo humano secuenciado con esta tecnología [3]. Estas nuevas tecnologías se fueron desarrollando en otras plataformas, tales como el secuenciador de roche 454, y el SOLiD de applied biosisten [3] y son conocidas como tecnologías de última generación o de siguiente generación (Next-generation sequencing, NGS), que tienen la capacidad de realizar secuenciaciones de alto rendimiento de una maneras más rápida y económica que las de primera generación [2]. La diferencia entre las técnicas de secuenciación de primera generación y las de NGS se presenta en el hecho de que la nueva generación genera lecturas de menos de 500 pares de bases en comparación a las 1000 pares de bases [3]. 

El desarrollo de estas tecnologías ha hecho que los datos biológicos aumenten de una manera vertiginosa, y permiten que se pueda realizar análisis de genómicos de diferentes organismos, análisis de ARN, que permiten aplicaciones en biotecnología y salud [4]. En el campo de la salud actualmente se emplea la secuenciación de exomas principalmente puesto que se considera que los exones son las regiones de ADN conservadas y expresadas, (se traducirán en ARNm y posteriormente en proteínas) y representan menos del 2% el genoma humano pero se estima que contiene el 85% de las variantes conocidas de enfermedades, lo que permite la reducción de costos y una buena alternativa frente a la secuenciación de genomas completos [5] [6]. 

La secuenciación de exones (secuenciación de exoma) ha sido un buen método para identificar SNPs (Polimorfismos de Nucleótido Único), y permitió identificar pequeñas delecciones o inserciones (indels) que pueden  ser la causa de enfermedades y de la variación en los fenotipos [7]. MiSeq es un sistema de secuenciación de illumina que permite la secuenciación de 4800 genes en un solo experimento [6]. En cuanto al análisis de los datos esta plataforma incluye un servició de computación en la nube (BaseSpace), donde los datos biológicos son analizados  sin necesidad de que los investigadores tengan habilidades en bioinformática. Pero están disponibles como herramientas solamente de investigación y no como diagnóstico [8] . 

A pesar de ser herramientas de investigación  que han sido desarrolladas, Illumina permite que dentro del BaseSpace se publiquen nuevos algoritmos, herramientas abiertas o aplicaciones diseñadas por desarrolladores que permitan mejorar estos análisis genómicos y con la aplicación en diversas plataformas de secuenciación que ofrece esta empresa [9].

Los datos obtenidos a partir de técnicas de NGS han tenido un crecimiento vertiginoso y presentan un reto para el manejo y análisis de los mismos, debido a que los formatos de los datos y las inconsistencias de las secuencias como resultado de los procesos experimentales, la importación de las secuencias a nivel digital, el ensamble de los fragmentos de ADN, el alineamiento y post-alineamiento de grandes cantidades de datos biológicos hace que se convierta en una de las bases de la investigación en bioinformática [7] [10].

Datos biológicos como “big data”.

En la era de las omícas, los datos se presentan en diferentes formas y en varios niveles en términos biológicos, los cuales incluyen los datos genómicos, datos de transcriptomica, epigenomica, metabulomica, entre otros, donde se incluyen también las diferentes datos poblacionales humanos y las historias clínicas, la escala de estos datos se encuentran  entre  pentabyte y exabyte [11]. La definición de “big data” es muy discutido dentro de las ciencias de la información, sin embargo el nombre  hace referencia a la “gran cantidad de datos” que se caracterizan por el volumen del procesamiento, la variabilidad de los mismos y la veracidad de la calidad de los datos [11]. Partiendo de lo anterior los datos biologícos pueden ser catalogados como “big data” ya que poseen las siguientes características: Son numerosos, no pueden ser almacenados dentro de una base regular de datos, la velocidad  de generación y procesamiento es muy rápida [12].

Para el manejo de los datos se han aplicado varios modelos de sistemas de información en  bioinformática con diversas herramientas para integrar datos biológicos, utilizando sistemas de bodega de datos que están disponibles de manera gratuita y que fueron desarrollados con el fin de dar respuesta algunos de los problemas en el manejo de datos biológicos, dada la importancia que tiene de poder utilizar toda la información necesaria de manera eficiente [10]. En la tabla 1 se describen algunos softwares libres para la integración de datos:
